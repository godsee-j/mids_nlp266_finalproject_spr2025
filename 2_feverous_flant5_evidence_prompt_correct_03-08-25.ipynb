{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6JY-FCThpss4"},"outputs":[],"source":["def prepare_training_data(input_file, output_file):\n","    \"\"\"Convert processed FEVEROUS data to training-ready format\"\"\"\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    training_examples = []\n","    claims = data[\"processed_claims\"]\n","\n","    for claim in tqdm(claims, desc=\"Preparing examples\"):\n","        # Basic claim information\n","        example = {\n","            \"id\": claim.get(\"id\", \"\"),\n","            \"claim\": claim.get(\"claim\", \"\"),\n","            \"verdict\": claim.get(\"verdict\", \"\"),\n","            \"evidence_count\": sum(len(ev_set) for ev_set in claim.get(\"evidence\", [])),\n","            \"evidence_sets\": []\n","        }\n","\n","        # Process evidence sets\n","        for ev_set_idx, ev_set in enumerate(claim.get(\"evidence\", [])):\n","            formatted_set = []\n","            for ev_piece in ev_set:\n","                # Extract source from ID\n","                source = ev_piece.get(\"id\", \"\").split(\"_\")[0] if \"_\" in ev_piece.get(\"id\", \"\") else \"unknown\"\n","\n","                formatted_set.append({\n","                    \"content\": ev_piece.get(\"content\", \"\"),\n","                    \"source\": source,\n","                    \"type\": determine_evidence_type(ev_piece.get(\"id\", \"\")),\n","                })\n","\n","            example[\"evidence_sets\"].append(formatted_set)\n","\n","        training_examples.append(example)\n","\n","    # Save to file\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": training_examples}, f)\n","\n","    print(f\"Saved {len(training_examples)} examples to {output_file}\")\n","\n","def determine_evidence_type(ev_id):\n","    \"\"\"Determine evidence type from ID\"\"\"\n","    if \"_sentence_\" in ev_id:\n","        return \"sentence\"\n","    elif \"_cell_\" in ev_id:\n","        return \"table_cell\"\n","    elif \"_item_\" in ev_id:\n","        return \"list_item\"\n","    else:\n","        return \"other\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcNSk1m0pss_"},"outputs":[],"source":["def split_into_chunks(input_file, output_dir, chunk_size=10000):\n","    \"\"\"Split large dataset into manageable chunks\"\"\"\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = data[\"examples\"]\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Split into chunks\n","    for i in range(0, len(examples), chunk_size):\n","        chunk = examples[i:i+chunk_size]\n","        chunk_file = os.path.join(output_dir, f\"feverous_chunk_{i//chunk_size}.json\")\n","\n","        with open(chunk_file, 'w', encoding='utf-8') as f:\n","            json.dump({\"examples\": chunk}, f)\n","\n","        print(f\"Saved chunk {i//chunk_size} with {len(chunk)} examples to {chunk_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzqfw-7Jpss_"},"outputs":[],"source":["def create_stratified_samples(input_file, output_dir, sample_size=5000):\n","    \"\"\"Create stratified samples for balanced training\"\"\"\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = data[\"examples\"]\n","\n","    # Group by verdict\n","    by_verdict = {\n","        \"SUPPORTS\": [],\n","        \"REFUTES\": [],\n","        \"NOT ENOUGH INFO\": []\n","    }\n","\n","    for example in examples:\n","        verdict = example[\"verdict\"]\n","        if verdict in by_verdict:\n","            by_verdict[verdict].append(example)\n","\n","    # Create balanced sample\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Calculate samples per class\n","    total_classes = len(by_verdict)\n","    per_class = sample_size // total_classes\n","\n","    balanced_sample = []\n","    for verdict, examples in by_verdict.items():\n","        # Take random sample or all if not enough\n","        sample_count = min(per_class, len(examples))\n","        sampled = random.sample(examples, sample_count)\n","        balanced_sample.extend(sampled)\n","        print(f\"Added {sample_count} {verdict} examples\")\n","\n","    # Shuffle final sample\n","    random.shuffle(balanced_sample)\n","\n","    # Save balanced sample\n","    sample_file = os.path.join(output_dir, f\"feverous_balanced_{sample_size}.json\")\n","    with open(sample_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": balanced_sample}, f)\n","\n","    print(f\"Saved balanced sample with {len(balanced_sample)} examples to {sample_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndPokObopstA"},"outputs":[],"source":["def create_prompt_files(input_file, output_dir):\n","    \"\"\"Create files with pre-formatted prompts\"\"\"\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = data[\"examples\"]\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    formatted_examples = []\n","    for example in tqdm(examples, desc=\"Formatting prompts\"):\n","        # Format evidence text\n","        formatted_evidence = []\n","        for i, ev_set in enumerate(example[\"evidence_sets\"]):\n","            for j, ev_piece in enumerate(ev_set):\n","                source = ev_piece[\"source\"]\n","                content = ev_piece[\"content\"]\n","                ev_type = ev_piece[\"type\"]\n","\n","                formatted_evidence.append(\n","                    f\"Evidence {len(formatted_evidence)+1} (from {source} article{', table' if ev_type == 'table_cell' else ''}): {content}\"\n","                )\n","\n","        # Create prompt\n","        prompt = f\"\"\"Instruction: Analyze the following claim and evidence to determine if the claim is supported, refuted, or cannot be determined from the evidence provided.\n","\n","Claim: {example[\"claim\"]}\n","\n","Evidence:\n","{chr(10).join(formatted_evidence)}\n","\n","Question: Based on the evidence, does the claim appear to be SUPPORTED, REFUTED, or NOT ENOUGH INFORMATION?\"\"\"\n","\n","        formatted_examples.append({\n","            \"id\": example[\"id\"],\n","            \"prompt\": prompt,\n","            \"verdict\": example[\"verdict\"]\n","        })\n","\n","    # Save formatted prompts\n","    output_file = os.path.join(output_dir, \"feverous_formatted_prompts.json\")\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": formatted_examples}, f)\n","\n","    print(f\"Saved {len(formatted_examples)} formatted prompts to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4hYf5rPpstB"},"outputs":[],"source":["def create_tfrecords(input_file, output_dir):\n","    \"\"\"Create TFRecord files for TensorFlow training\"\"\"\n","    import tensorflow as tf\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = data[\"examples\"]\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create label mapping\n","    label_map = {\n","        \"SUPPORTS\": 0,\n","        \"REFUTES\": 1,\n","        \"NOT ENOUGH INFO\": 2\n","    }\n","\n","    def _bytes_feature(value):\n","        \"\"\"Returns a bytes_list feature.\"\"\"\n","        if isinstance(value, type(tf.constant(0))):\n","            value = value.numpy()\n","        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","    def _int64_feature(value):\n","        \"\"\"Returns an int64_list feature.\"\"\"\n","        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","    # Write TFRecords in chunks\n","    chunk_size = 5000\n","    for i in range(0, len(examples), chunk_size):\n","        chunk = examples[i:i+chunk_size]\n","        output_file = os.path.join(output_dir, f\"feverous_chunk_{i//chunk_size}.tfrecord\")\n","\n","        with tf.io.TFRecordWriter(output_file) as writer:\n","            for example in tqdm(chunk, desc=f\"Writing chunk {i//chunk_size}\"):\n","                claim = example[\"claim\"]\n","\n","                # Format evidence\n","                evidence_text = \"\"\n","                for ev_set in example[\"evidence_sets\"]:\n","                    for ev_piece in ev_set:\n","                        evidence_text += f\"{ev_piece['source']}: {ev_piece['content']}\\n\"\n","\n","                # Create TF Example\n","                tf_example = tf.train.Example(features=tf.train.Features(feature={\n","                    'id': _bytes_feature(example[\"id\"].encode('utf-8')),\n","                    'claim': _bytes_feature(claim.encode('utf-8')),\n","                    'evidence': _bytes_feature(evidence_text.encode('utf-8')),\n","                    'label': _int64_feature(label_map.get(example[\"verdict\"], 2))\n","                }))\n","\n","                writer.write(tf_example.SerializeToString())\n","\n","        print(f\"Saved {len(chunk)} examples to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9-XMP0OpstC"},"outputs":[],"source":["def create_pytorch_files(input_file, output_dir):\n","    \"\"\"Create files for PyTorch training\"\"\"\n","    import torch\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = data[\"examples\"]\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Create label mapping\n","    label_map = {\n","        \"SUPPORTS\": 0,\n","        \"REFUTES\": 1,\n","        \"NOT ENOUGH INFO\": 2\n","    }\n","\n","    # Prepare examples\n","    processed_examples = []\n","    for example in tqdm(examples, desc=\"Processing for PyTorch\"):\n","        # Format evidence\n","        evidence_text = \"\"\n","        for ev_set in example[\"evidence_sets\"]:\n","            for ev_piece in ev_set:\n","                evidence_text += f\"{ev_piece['source']}: {ev_piece['content']}\\n\"\n","\n","        processed_examples.append({\n","            \"id\": example[\"id\"],\n","            \"claim\": example[\"claim\"],\n","            \"evidence\": evidence_text,\n","            \"label\": label_map.get(example[\"verdict\"], 2)\n","        })\n","\n","    # Save as pickle file\n","    output_file = os.path.join(output_dir, \"feverous_pytorch.pkl\")\n","    with open(output_file, 'wb') as f:\n","        torch.save(processed_examples, f)\n","\n","    print(f\"Saved {len(processed_examples)} examples to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdE6nRLepstC"},"outputs":[],"source":["def process_feverous_for_training(input_train, input_dev, output_dir):\n","    \"\"\"Complete pipeline for processing FEVEROUS data for training\"\"\"\n","    # Create base output directory\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Step 1: Convert to standard format\n","    train_standard = os.path.join(output_dir, \"feverous_train_standard.json\")\n","    dev_standard = os.path.join(output_dir, \"feverous_dev_standard.json\")\n","\n","    prepare_training_data(input_train, train_standard)\n","    prepare_training_data(input_dev, dev_standard)\n","\n","    # Step 2: Create chunks for training set\n","    train_chunks_dir = os.path.join(output_dir, \"train_chunks\")\n","    split_into_chunks(train_standard, train_chunks_dir)\n","\n","    # Step 3: Create stratified samples\n","    samples_dir = os.path.join(output_dir, \"stratified_samples\")\n","    create_stratified_samples(train_standard, samples_dir)\n","\n","    # Step 4: Create formatted prompts\n","    prompts_dir = os.path.join(output_dir, \"formatted_prompts\")\n","    create_prompt_files(train_standard, prompts_dir)\n","    create_prompt_files(dev_standard, prompts_dir)\n","\n","    # Step 5: Create framework-specific files\n","    tf_dir = os.path.join(output_dir, \"tensorflow\")\n","    pt_dir = os.path.join(output_dir, \"pytorch\")\n","\n","    create_tfrecords(train_standard, tf_dir)\n","    create_tfrecords(dev_standard, tf_dir)\n","\n","    create_pytorch_files(train_standard, pt_dir)\n","    create_pytorch_files(dev_standard, pt_dir)\n","\n","    print(\"Complete FEVEROUS processing pipeline finished!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ga3FFQQpstD"},"outputs":[],"source":["import json\n","import os\n","import random\n","from tqdm import tqdm\n","\n","def prepare_training_data(input_file, output_file):\n","    \"\"\"Convert processed FEVEROUS data to a clean, training-ready format\"\"\"\n","    print(f\"Processing {input_file}...\")\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    claims = data[\"processed_claims\"]\n","    print(f\"Found {len(claims)} claims\")\n","\n","    # Create a clean, simplified format\n","    training_examples = []\n","\n","    for claim in tqdm(claims, desc=\"Processing claims\"):\n","        # Basic claim information\n","        example = {\n","            \"id\": claim.get(\"id\", \"\"),\n","            \"claim\": claim.get(\"claim\", \"\"),\n","            \"verdict\": claim.get(\"verdict\", \"\"),\n","            \"evidence\": []\n","        }\n","\n","        # Process all evidence pieces\n","        for ev_set in claim.get(\"evidence\", []):\n","            evidence_set = []\n","            for ev_piece in ev_set:\n","                # Determine evidence type\n","                ev_id = ev_piece.get(\"id\", \"\")\n","                if \"_sentence_\" in ev_id:\n","                    ev_type = \"sentence\"\n","                elif \"_cell_\" in ev_id:\n","                    ev_type = \"table_cell\"\n","                elif \"_item_\" in ev_id:\n","                    ev_type = \"list_item\"\n","                else:\n","                    ev_type = \"other\"\n","\n","                # Extract source document\n","                source = ev_id.split(\"_\")[0] if \"_\" in ev_id else \"unknown\"\n","\n","                # Add formatted evidence\n","                evidence_set.append({\n","                    \"content\": ev_piece.get(\"content\", \"\"),\n","                    \"type\": ev_type,\n","                    \"source\": source\n","                })\n","\n","            example[\"evidence\"].append(evidence_set)\n","\n","        training_examples.append(example)\n","\n","    # Save to file\n","    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": training_examples}, f, indent=2)\n","\n","    print(f\"Saved {len(training_examples)} examples to {output_file}\")\n","    return training_examples\n","\n","def create_prompt_files(examples, output_file):\n","    \"\"\"Create files with formatted prompts for training\"\"\"\n","    print(\"Creating formatted prompts...\")\n","\n","    formatted_examples = []\n","    for example in tqdm(examples, desc=\"Formatting prompts\"):\n","        # Format all evidence pieces\n","        all_evidence = []\n","        for ev_set_idx, ev_set in enumerate(example[\"evidence\"]):\n","            for ev_piece in ev_set:\n","                source = ev_piece[\"source\"]\n","                content = ev_piece[\"content\"]\n","                ev_type = ev_piece[\"type\"]\n","\n","                formatted_ev = f\"Evidence {len(all_evidence)+1}\"\n","                formatted_ev += f\" (from {source}\"\n","                if ev_type == \"table_cell\":\n","                    formatted_ev += \", table\"\n","                elif ev_type == \"list_item\":\n","                    formatted_ev += \", list\"\n","                formatted_ev += f\"): {content}\"\n","\n","                all_evidence.append(formatted_ev)\n","\n","        # Create prompt\n","        prompt = f\"\"\"Instruction: Analyze the following claim and evidence to determine if the claim is supported, refuted, or cannot be determined from the evidence provided.\n","\n","Claim: {example[\"claim\"]}\n","\n","Evidence:\n","{chr(10).join(all_evidence)}\n","\n","Question: Based on the evidence, does the claim appear to be SUPPORTED, REFUTED, or NOT ENOUGH INFORMATION?\"\"\"\n","\n","        formatted_examples.append({\n","            \"id\": example[\"id\"],\n","            \"prompt\": prompt,\n","            \"verdict\": example[\"verdict\"]\n","        })\n","\n","    # Save formatted prompts\n","    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": formatted_examples}, f, indent=2)\n","\n","    print(f\"Saved {len(formatted_examples)} formatted prompts to {output_file}\")\n","\n","def main():\n","    # Create output directory\n","    output_dir = \"feverous_prepared\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Process training data\n","    train_examples = prepare_training_data(\n","        \"train_all_processed.json\",\n","        os.path.join(output_dir, \"feverous_train.json\")\n","    )\n","\n","    # Process dev data\n","    dev_examples = prepare_training_data(\n","        \"dev_all_processed.json\",\n","        os.path.join(output_dir, \"feverous_dev.json\")\n","    )\n","\n","    # Create prompt files\n","    create_prompt_files(\n","        train_examples,\n","        os.path.join(output_dir, \"feverous_train_prompts.json\")\n","    )\n","\n","    create_prompt_files(\n","        dev_examples,\n","        os.path.join(output_dir, \"feverous_dev_prompts.json\")\n","    )\n","\n","    print(\"FEVEROUS data preparation complete!\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NocHx47MpstE"},"outputs":[],"source":["# Example loading code\n","with open(\"feverous_prepared/feverous_train_prompts.json\", \"r\") as f:\n","    training_data = json.load(f)[\"examples\"]\n","\n","for example in training_data:\n","    prompt = example[\"prompt\"]\n","    label = example[\"verdict\"]\n","    # Use in your training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1t8jhyaZpstE"},"outputs":[],"source":["import json\n","import os\n","import random\n","from tqdm import tqdm\n","\n","def prepare_training_data(input_file, output_file):\n","    \"\"\"Convert processed FEVEROUS data to a clean, training-ready format\"\"\"\n","    print(f\"Processing {input_file}...\")\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    claims = data[\"processed_claims\"]\n","    print(f\"Found {len(claims)} claims\")\n","\n","    # Create a clean, simplified format\n","    training_examples = []\n","\n","    for claim in tqdm(claims, desc=\"Processing claims\"):\n","        # Basic claim information\n","        example = {\n","            \"id\": claim.get(\"id\", \"\"),\n","            \"claim\": claim.get(\"claim\", \"\"),\n","            \"verdict\": claim.get(\"verdict\", \"\"),\n","            \"evidence\": []\n","        }\n","\n","        # Process all evidence pieces\n","        for ev_set in claim.get(\"evidence\", []):\n","            evidence_set = []\n","            for ev_piece in ev_set:\n","                # Determine evidence type\n","                ev_id = ev_piece.get(\"id\", \"\")\n","                if \"_sentence_\" in ev_id:\n","                    ev_type = \"sentence\"\n","                elif \"_cell_\" in ev_id:\n","                    ev_type = \"table_cell\"\n","                elif \"_item_\" in ev_id:\n","                    ev_type = \"list_item\"\n","                else:\n","                    ev_type = \"other\"\n","\n","                # Extract source document\n","                source = ev_id.split(\"_\")[0] if \"_\" in ev_id else \"unknown\"\n","\n","                # Add formatted evidence\n","                evidence_set.append({\n","                    \"content\": ev_piece.get(\"content\", \"\"),\n","                    \"type\": ev_type,\n","                    \"source\": source\n","                })\n","\n","            example[\"evidence\"].append(evidence_set)\n","\n","        training_examples.append(example)\n","\n","    # Save to file\n","    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": training_examples}, f, indent=2)\n","\n","    print(f\"Saved {len(training_examples)} examples to {output_file}\")\n","    return training_examples\n","\n","def create_prompt_files(examples, output_file):\n","    \"\"\"Create files with formatted prompts for training\"\"\"\n","    print(\"Creating formatted prompts...\")\n","\n","    formatted_examples = []\n","    for example in tqdm(examples, desc=\"Formatting prompts\"):\n","        # Format all evidence pieces\n","        all_evidence = []\n","        for ev_set_idx, ev_set in enumerate(example[\"evidence\"]):\n","            for ev_piece in ev_set:\n","                source = ev_piece[\"source\"]\n","                content = ev_piece[\"content\"]\n","                ev_type = ev_piece[\"type\"]\n","\n","                formatted_ev = f\"Evidence {len(all_evidence)+1}\"\n","                formatted_ev += f\" (from {source}\"\n","                if ev_type == \"table_cell\":\n","                    formatted_ev += \", table\"\n","                elif ev_type == \"list_item\":\n","                    formatted_ev += \", list\"\n","                formatted_ev += f\"): {content}\"\n","\n","                all_evidence.append(formatted_ev)\n","\n","        # Create prompt\n","        prompt = f\"\"\"Instruction: Analyze the following claim and evidence to determine if the claim is supported, refuted, or cannot be determined from the evidence provided.\n","\n","Claim: {example[\"claim\"]}\n","\n","Evidence:\n","{chr(10).join(all_evidence)}\n","\n","Question: Based on the evidence, does the claim appear to be SUPPORTED, REFUTED, or NOT ENOUGH INFORMATION?\"\"\"\n","\n","        formatted_examples.append({\n","            \"id\": example[\"id\"],\n","            \"prompt\": prompt,\n","            \"verdict\": example[\"verdict\"]\n","        })\n","\n","    # Save formatted prompts\n","    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        json.dump({\"examples\": formatted_examples}, f, indent=2)\n","\n","    print(f\"Saved {len(formatted_examples)} formatted prompts to {output_file}\")\n","\n","def main():\n","    # Create output directory\n","    output_dir = \"feverous_prepared\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Process training data\n","    train_examples = prepare_training_data(\n","        \"train_all_processed.json\",\n","        os.path.join(output_dir, \"feverous_train.json\")\n","    )\n","\n","    # Process dev data\n","    dev_examples = prepare_training_data(\n","        \"dev_all_processed.json\",\n","        os.path.join(output_dir, \"feverous_dev.json\")\n","    )\n","\n","    # Create prompt files\n","    create_prompt_files(\n","        train_examples,\n","        os.path.join(output_dir, \"feverous_train_prompts.json\")\n","    )\n","\n","    create_prompt_files(\n","        dev_examples,\n","        os.path.join(output_dir, \"feverous_dev_prompts.json\")\n","    )\n","\n","    print(\"FEVEROUS data preparation complete!\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}